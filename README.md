
# Finetuning LLama2 using PEFT (LoRA)

This repository provides guidelines and resources for finetuning the LLama2 (Large Language Model) using the PEFT (Parameter Efficient Finetuning) technique, specifically the LoRA (Low-resource Adaptation) variant.

# Dataset:
### Name: openassistant-guanaco
### Link: https://huggingface.co/datasets/timdettmers/openassistant-guanaco

# Overview
LLama2 is a powerful large language model pretrained on a vast corpus of text data, capable of understanding and generating human-like text. Finetuning LLama2 using PEFT (LoRA) allows adapting the model to specific tasks or domains with limited Compute Resources.

# Screenshots
### LLama2 Prompt Template
![App Screenshot](images/img1.png)



# Usage:
- Clone the Repository
- Open the "LLAMA FINETUNING.ipynb" notebook in jupyter 
- Install the required libraries mentioned in the jupyter notebook
- Run all the cells.
